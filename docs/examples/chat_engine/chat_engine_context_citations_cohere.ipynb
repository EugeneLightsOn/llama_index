{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a9691d675c518e9",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/examples/chat_engine/chat_engine_context_citations_cohere.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b938b29100cde228",
   "metadata": {},
   "source": [
    "Cohere Chat Engine with citations and documents - Usage Example\n",
    "========================================\n",
    "    \n",
    "This notebook demonstrates how to use the Cohere chat engine to generate responses to user input with citations and context documents(Cohere documents mode - see the documentation [here](https://docs.cohere.com/docs/retrieval-augmented-generation-rag) and [here](https://docs.cohere.com/docs/retrieval-augmented-generation-rag). Cohere Chat Engine provides several modes for generating responses, including: Chat, Async Chat, Stream Chat and Async Stream Chat. We will use a vector index to retrieve the context documents and the next sample [data](https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt) \n",
    "\n",
    "\n",
    "\n",
    "Download Data\n",
    "========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9ba7968d75b307",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2165c037b8c63bcd",
   "metadata": {},
   "source": [
    "Install requirements\n",
    "========================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce05a5b1d0199c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index\n",
    "%pip install llama-index-llms-cohere\n",
    "%pip install llama-index-embeddings-cohere\n",
    "%pip install cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe1a51034616ee6",
   "metadata": {},
   "source": [
    "Let's start by creating a new index and adding the context documents into it.\n",
    "========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d728e6c512eaf",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3db338063b98b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.embeddings.cohere import CohereEmbedding\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.cohere import Cohere\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516e2f2da08f6b9",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a64b6255b4bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"COHERE_API_KEY\"] = \"YOUR_COHERE_API_KEY_HERE\"\n",
    "COHERE_API_KEY = os.environ[\"COHERE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd78554cf75b40",
   "metadata": {},
   "source": [
    "### Create a new Cohere LLM instance and register it in settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1904b8b2d3fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = Cohere(\n",
    "    \"command\",\n",
    "    api_key=COHERE_API_KEY,\n",
    "    temperature=0.5,\n",
    "    additional_kwargs={\"prompt_truncation\": \"AUTO\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1763b8035a964c88",
   "metadata": {},
   "source": [
    "### Create a new Cohere embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24545f37bb8b72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cohere_embed_model(\n",
    "    input_type=\"search_document\", model_name=\"embed-english-v3.0\"\n",
    "):\n",
    "    cohere_embed_model = CohereEmbedding(\n",
    "        cohere_api_key=COHERE_API_KEY,\n",
    "        model_name=model_name,\n",
    "        input_type=input_type,\n",
    "    )\n",
    "\n",
    "    return cohere_embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32147d36841884af",
   "metadata": {},
   "source": [
    "### Create a new service context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c066f044e8bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cohere_service_context(input_type=\"search_document\"):\n",
    "    Settings.llm = LLM\n",
    "    Settings.embed_model = get_cohere_embed_model(input_type=input_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c974fd92480701",
   "metadata": {},
   "source": [
    "### Read the sample documents from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385194abb2092df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_documents(path=\"./data/paul_graham/\"):\n",
    "    sample_documents = SimpleDirectoryReader(input_dir=path).load_data()\n",
    "    return sample_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ddeb14cb1cf463",
   "metadata": {},
   "source": [
    "### For the Chat Engine we should use Cohere embed model with input type \"search_query\". See the [documentation](https://docs.cohere.com/reference/embed) for more details. So we need to use a new index with the input type \"search_query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e16a59f288f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opensearch_query_index():\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        get_sample_documents(),\n",
    "        embed_model=get_cohere_embed_model(input_type=\"search_query\"),\n",
    "    )\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287d65e488123bb",
   "metadata": {},
   "source": [
    "### And finally, we can create a new chat engine using Cohere Context mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185577d42fb1080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_engine_by_index_and_mode(index, mode=\"citations_context\"):\n",
    "    chat_engine = index.as_chat_engine(chat_mode=mode, llm=LLM)\n",
    "    return chat_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bee302f3959a6c2",
   "metadata": {},
   "source": [
    "## Let's run it and see the results\n",
    "### Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5c3e4d2c58e985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham reverse-engineered SHRDLU as an undergraduate for his thesis. SHRDLU was a PBS documentary that showed Terry Winograd using SHRDLU, and Paul Graham believed that it was already climbing the lower slopes of intelligence. He said that in the 80s, it was a stimulating bit of code and he enjoyed working with it. He was fascinated by the idea that if SHRDLU's vocabulary was expanded, it would quickly learn to mimic human language.\n",
      "Citations: [Citation(text='reverse-engineered SHRDLU', start=12, end=37, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='PBS documentary', start=87, end=102, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='Terry Winograd using SHRDLU', start=115, end=142, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='climbing the lower slopes of intelligence.', start=189, end=231, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='stimulating bit of code', start=266, end=289, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='vocabulary was expanded', start=369, end=392, document_ids=['7451555d-c245-42c1-90fe-180df5af233c'])]\n",
      "Documents: [Document(id='7451555d-c245-42c1-90fe-180df5af233c', text='I couldn\\'t have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\\n\\nAI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven\\'t tried rereading The Moon is a Harsh Mistress, so I don\\'t know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we\\'d have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most. All you had to do was teach SHRDLU more words.\\n\\nThere weren\\'t any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp, since in those days Lisp was regarded as the language of AI. The commonly used programming languages then were pretty primitive, and programmers\\' ideas correspondingly so. The default language at Cornell was a Pascal-like language called PL/I, and the situation was similar elsewhere. Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were. This was more like it; this was what I had expected college to do. It wasn\\'t happening in a class, like it was supposed to, but that was ok. For the next couple years I was on a roll. I knew what I was going to do.\\n\\nFor my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program. It was a pleasing bit of code, but what made it even more exciting was my belief — hard to imagine now, but not unique in 1985 — that it was already climbing the lower slopes of intelligence.\\n\\nI had gotten into a program at Cornell that didn\\'t make you choose a major. You could take whatever classes you liked, and choose whatever you liked to put on your degree. I of course chose \"Artificial Intelligence.\" When I got the actual physical diploma, I was dismayed to find that the quotes had been included, which made them read as scare-quotes. At the time this bothered me, but now it seems amusingly accurate, for reasons I was about to discover.\\n\\nI applied to 3 grad schools: MIT and Yale, which were renowned for AI at the time, and Harvard, which I\\'d visited because Rich Draves went there, and was also home to Bill Woods, who\\'d invented the type of parser I used in my SHRDLU clone. Only Harvard accepted me, so that was where I went.\\n\\nI don\\'t remember the moment it happened, or if there even was a specific moment, but during the first year of grad school I realized that AI, as practiced at the time, was a hoax. By which I mean the sort of AI in which a program that\\'s told \"the dog is sitting on the chair\" translates this into some formal representation and adds it to the list of things it knows.\\n\\nWhat these programs really showed was that there\\'s a subset of natural language that\\'s a formal language. But a very proper subset. It was clear that there was an unbridgeable gap between what they could do and actually understanding natural language. It was not, in fact, simply a matter of teaching SHRDLU more words. That whole way of doing AI, with explicit data structures representing concepts, was not going to work. Its brokenness did, as so often happens, generate a lot of opportunities to write papers about various band-aids that could be applied to it, but it was never going to get us Mike.\\n\\nSo I looked around to see what I could salvage from the wreckage of my plans, and there was Lisp. I knew from experience that Lisp was interesting for its own sake and not just for its association with AI, even though that was the main reason people cared about it at the time. So I decided to focus on Lisp. In fact, I decided to write a book about Lisp hacking. It\\'s scary to think how little I knew about Lisp hacking when I started writing that book. But there\\'s nothing like writing a book about something to help you learn it. The book, On Lisp, wasn\\'t published till 1993, but I wrote much of it in grad school.\\n\\nComputer Science is an uneasy alliance between two halves, theory and systems. The theory people prove things, and the systems people build things. I wanted to build things.')]\n"
     ]
    }
   ],
   "source": [
    "# Set service context using Settings\n",
    "set_cohere_service_context()\n",
    "# fill_opensearch_documents_index()\n",
    "# Create a new chat engine\n",
    "chat_engine = get_chat_engine_by_index_and_mode(get_opensearch_query_index())\n",
    "\n",
    "# Ask a question using the chat engine\n",
    "question = \"What did Paul Graham do with SHRDLU?\"\n",
    "llm_response = chat_engine.chat(question)\n",
    "# Print the response\n",
    "print(llm_response)\n",
    "# Print the citations\n",
    "print(f\"Citations: {llm_response.citations}\")\n",
    "# Print the context documents\n",
    "print(f\"Documents: {llm_response.documents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb63af9016036ad",
   "metadata": {},
   "source": [
    "### Async Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21667cd91877db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For his undergraduate thesis, Paul Graham reverse-engineered SHRDLU. He later realised that the AI practices at the time were a hoax and that there was an unbridgeable gap between what they could do and understanding natural language.\n",
      "Citations: [Citation(text='undergraduate thesis', start=8, end=28, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='reverse-engineered SHRDLU.', start=42, end=68, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='the AI practices at the time were a hoax', start=92, end=132, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='unbridgeable gap', start=155, end=171, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='understanding natural language.', start=203, end=234, document_ids=['7451555d-c245-42c1-90fe-180df5af233c'])]\n",
      "Documents: [Document(id='7451555d-c245-42c1-90fe-180df5af233c', text='I couldn\\'t have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\\n\\nAI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven\\'t tried rereading The Moon is a Harsh Mistress, so I don\\'t know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we\\'d have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most. All you had to do was teach SHRDLU more words.\\n\\nThere weren\\'t any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp, since in those days Lisp was regarded as the language of AI. The commonly used programming languages then were pretty primitive, and programmers\\' ideas correspondingly so. The default language at Cornell was a Pascal-like language called PL/I, and the situation was similar elsewhere. Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were. This was more like it; this was what I had expected college to do. It wasn\\'t happening in a class, like it was supposed to, but that was ok. For the next couple years I was on a roll. I knew what I was going to do.\\n\\nFor my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program. It was a pleasing bit of code, but what made it even more exciting was my belief — hard to imagine now, but not unique in 1985 — that it was already climbing the lower slopes of intelligence.\\n\\nI had gotten into a program at Cornell that didn\\'t make you choose a major. You could take whatever classes you liked, and choose whatever you liked to put on your degree. I of course chose \"Artificial Intelligence.\" When I got the actual physical diploma, I was dismayed to find that the quotes had been included, which made them read as scare-quotes. At the time this bothered me, but now it seems amusingly accurate, for reasons I was about to discover.\\n\\nI applied to 3 grad schools: MIT and Yale, which were renowned for AI at the time, and Harvard, which I\\'d visited because Rich Draves went there, and was also home to Bill Woods, who\\'d invented the type of parser I used in my SHRDLU clone. Only Harvard accepted me, so that was where I went.\\n\\nI don\\'t remember the moment it happened, or if there even was a specific moment, but during the first year of grad school I realized that AI, as practiced at the time, was a hoax. By which I mean the sort of AI in which a program that\\'s told \"the dog is sitting on the chair\" translates this into some formal representation and adds it to the list of things it knows.\\n\\nWhat these programs really showed was that there\\'s a subset of natural language that\\'s a formal language. But a very proper subset. It was clear that there was an unbridgeable gap between what they could do and actually understanding natural language. It was not, in fact, simply a matter of teaching SHRDLU more words. That whole way of doing AI, with explicit data structures representing concepts, was not going to work. Its brokenness did, as so often happens, generate a lot of opportunities to write papers about various band-aids that could be applied to it, but it was never going to get us Mike.\\n\\nSo I looked around to see what I could salvage from the wreckage of my plans, and there was Lisp. I knew from experience that Lisp was interesting for its own sake and not just for its association with AI, even though that was the main reason people cared about it at the time. So I decided to focus on Lisp. In fact, I decided to write a book about Lisp hacking. It\\'s scary to think how little I knew about Lisp hacking when I started writing that book. But there\\'s nothing like writing a book about something to help you learn it. The book, On Lisp, wasn\\'t published till 1993, but I wrote much of it in grad school.\\n\\nComputer Science is an uneasy alliance between two halves, theory and systems. The theory people prove things, and the systems people build things. I wanted to build things.')]\n"
     ]
    }
   ],
   "source": [
    "llm_response = await chat_engine.achat(question)\n",
    "print(llm_response)\n",
    "print(f\"Citations: {llm_response.citations}\")\n",
    "print(f\"Documents: {llm_response.documents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6733606f1fa71a60",
   "metadata": {},
   "source": [
    "### Stream Chat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefefe581650b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For his undergraduate thesis, Paul Graham reverse-engineered SHRDLU and later discovered that the AI practices at the time were a hoax and that there was an unbridgeable gap between what they could do and understanding natural language.Citations: \n",
      "[Citation(text='undergraduate thesis', start=8, end=28, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='reverse-engineered SHRDLU', start=42, end=67, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='AI practices at the time were a hoax', start=98, end=134, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='unbridgeable gap between what they could do and understanding natural language.', start=157, end=236, document_ids=['7451555d-c245-42c1-90fe-180df5af233c'])]\n",
      "Documents: \n",
      "[Document(id='7451555d-c245-42c1-90fe-180df5af233c', text='I couldn\\'t have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\\n\\nAI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven\\'t tried rereading The Moon is a Harsh Mistress, so I don\\'t know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we\\'d have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most. All you had to do was teach SHRDLU more words.\\n\\nThere weren\\'t any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp, since in those days Lisp was regarded as the language of AI. The commonly used programming languages then were pretty primitive, and programmers\\' ideas correspondingly so. The default language at Cornell was a Pascal-like language called PL/I, and the situation was similar elsewhere. Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were. This was more like it; this was what I had expected college to do. It wasn\\'t happening in a class, like it was supposed to, but that was ok. For the next couple years I was on a roll. I knew what I was going to do.\\n\\nFor my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program. It was a pleasing bit of code, but what made it even more exciting was my belief — hard to imagine now, but not unique in 1985 — that it was already climbing the lower slopes of intelligence.\\n\\nI had gotten into a program at Cornell that didn\\'t make you choose a major. You could take whatever classes you liked, and choose whatever you liked to put on your degree. I of course chose \"Artificial Intelligence.\" When I got the actual physical diploma, I was dismayed to find that the quotes had been included, which made them read as scare-quotes. At the time this bothered me, but now it seems amusingly accurate, for reasons I was about to discover.\\n\\nI applied to 3 grad schools: MIT and Yale, which were renowned for AI at the time, and Harvard, which I\\'d visited because Rich Draves went there, and was also home to Bill Woods, who\\'d invented the type of parser I used in my SHRDLU clone. Only Harvard accepted me, so that was where I went.\\n\\nI don\\'t remember the moment it happened, or if there even was a specific moment, but during the first year of grad school I realized that AI, as practiced at the time, was a hoax. By which I mean the sort of AI in which a program that\\'s told \"the dog is sitting on the chair\" translates this into some formal representation and adds it to the list of things it knows.\\n\\nWhat these programs really showed was that there\\'s a subset of natural language that\\'s a formal language. But a very proper subset. It was clear that there was an unbridgeable gap between what they could do and actually understanding natural language. It was not, in fact, simply a matter of teaching SHRDLU more words. That whole way of doing AI, with explicit data structures representing concepts, was not going to work. Its brokenness did, as so often happens, generate a lot of opportunities to write papers about various band-aids that could be applied to it, but it was never going to get us Mike.\\n\\nSo I looked around to see what I could salvage from the wreckage of my plans, and there was Lisp. I knew from experience that Lisp was interesting for its own sake and not just for its association with AI, even though that was the main reason people cared about it at the time. So I decided to focus on Lisp. In fact, I decided to write a book about Lisp hacking. It\\'s scary to think how little I knew about Lisp hacking when I started writing that book. But there\\'s nothing like writing a book about something to help you learn it. The book, On Lisp, wasn\\'t published till 1993, but I wrote much of it in grad school.\\n\\nComputer Science is an uneasy alliance between two halves, theory and systems. The theory people prove things, and the systems people build things. I wanted to build things.'), Document(id='7b0c53b0-57b4-4730-a8f5-e0154ea702e7', text='When I was dealing with some urgent problem during YC, there was about a 60% chance it had to do with HN, and a 40% chance it had do with everything else combined. [17]\\n\\nAs well as HN, I wrote all of YC\\'s internal software in Arc. But while I continued to work a good deal in Arc, I gradually stopped working on Arc, partly because I didn\\'t have time to, and partly because it was a lot less attractive to mess around with the language now that we had all this infrastructure depending on it. So now my three projects were reduced to two: writing essays and working on YC.\\n\\nYC was different from other kinds of work I\\'ve done. Instead of deciding for myself what to work on, the problems came to me. Every 6 months there was a new batch of startups, and their problems, whatever they were, became our problems. It was very engaging work, because their problems were quite varied, and the good founders were very effective. If you were trying to learn the most you could about startups in the shortest possible time, you couldn\\'t have picked a better way to do it.\\n\\nThere were parts of the job I didn\\'t like. Disputes between cofounders, figuring out when people were lying to us, fighting with people who maltreated the startups, and so on. But I worked hard even at the parts I didn\\'t like. I was haunted by something Kevin Hale once said about companies: \"No one works harder than the boss.\" He meant it both descriptively and prescriptively, and it was the second part that scared me. I wanted YC to be good, so if how hard I worked set the upper bound on how hard everyone else worked, I\\'d better work very hard.\\n\\nOne day in 2010, when he was visiting California for interviews, Robert Morris did something astonishing: he offered me unsolicited advice. I can only remember him doing that once before. One day at Viaweb, when I was bent over double from a kidney stone, he suggested that it would be a good idea for him to take me to the hospital. That was what it took for Rtm to offer unsolicited advice. So I remember his exact words very clearly. \"You know,\" he said, \"you should make sure Y Combinator isn\\'t the last cool thing you do.\"\\n\\nAt the time I didn\\'t understand what he meant, but gradually it dawned on me that he was saying I should quit. This seemed strange advice, because YC was doing great. But if there was one thing rarer than Rtm offering advice, it was Rtm being wrong. So this set me thinking. It was true that on my current trajectory, YC would be the last thing I did, because it was only taking up more of my attention. It had already eaten Arc, and was in the process of eating essays too. Either YC was my life\\'s work or I\\'d have to leave eventually. And it wasn\\'t, so I would.\\n\\nIn the summer of 2012 my mother had a stroke, and the cause turned out to be a blood clot caused by colon cancer. The stroke destroyed her balance, and she was put in a nursing home, but she really wanted to get out of it and back to her house, and my sister and I were determined to help her do it. I used to fly up to Oregon to visit her regularly, and I had a lot of time to think on those flights. On one of them I realized I was ready to hand YC over to someone else.\\n\\nI asked Jessica if she wanted to be president, but she didn\\'t, so we decided we\\'d try to recruit Sam Altman. We talked to Robert and Trevor and we agreed to make it a complete changing of the guard. Up till that point YC had been controlled by the original LLC we four had started. But we wanted YC to last for a long time, and to do that it couldn\\'t be controlled by the founders. So if Sam said yes, we\\'d let him reorganize YC. Robert and I would retire, and Jessica and Trevor would become ordinary partners.\\n\\nWhen we asked Sam if he wanted to be president of YC, initially he said no. He wanted to start a startup to make nuclear reactors. But I kept at it, and in October 2013 he finally agreed. We decided he\\'d take over starting with the winter 2014 batch. For the rest of 2013 I left running YC more and more to Sam, partly so he could learn the job, and partly because I was focused on my mother, whose cancer had returned.')]\n"
     ]
    }
   ],
   "source": [
    "llm_response = chat_engine.stream_chat(question)\n",
    "llm_response.print_response_stream()\n",
    "\n",
    "print(\"Citations: \")\n",
    "print(llm_response.citations)\n",
    "\n",
    "print(\"Documents: \")\n",
    "print(llm_response.documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b31467e7c26b2",
   "metadata": {},
   "source": [
    "### Async Stream Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437fd5ec78dd905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham reverse-engineered SHRDLU as an undergraduate for his thesis. However, he later realised that the AI practices at the time were a hoax and that there was an unbridgeable gap between what they could do and understanding natural language. After this, he refocused on Lisp and wrote a book on it called On Lisp, which wasn't published until 1993.Citations: \n",
      "[Citation(text='reverse-engineered SHRDLU', start=12, end=37, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='undergraduate', start=44, end=57, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='thesis.', start=66, end=73, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='AI practices at the time were a hoax', start=110, end=146, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='unbridgeable gap', start=169, end=185, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='understanding natural language.', start=217, end=248, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='refocused on Lisp', start=264, end=281, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='wrote a book', start=286, end=298, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='On Lisp', start=312, end=319, document_ids=['7451555d-c245-42c1-90fe-180df5af233c']), Citation(text='published until 1993.', start=334, end=355, document_ids=['7451555d-c245-42c1-90fe-180df5af233c'])]\n",
      "Documents: \n",
      "[Document(id='7451555d-c245-42c1-90fe-180df5af233c', text='I couldn\\'t have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\\n\\nAI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven\\'t tried rereading The Moon is a Harsh Mistress, so I don\\'t know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we\\'d have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most. All you had to do was teach SHRDLU more words.\\n\\nThere weren\\'t any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp, since in those days Lisp was regarded as the language of AI. The commonly used programming languages then were pretty primitive, and programmers\\' ideas correspondingly so. The default language at Cornell was a Pascal-like language called PL/I, and the situation was similar elsewhere. Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were. This was more like it; this was what I had expected college to do. It wasn\\'t happening in a class, like it was supposed to, but that was ok. For the next couple years I was on a roll. I knew what I was going to do.\\n\\nFor my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program. It was a pleasing bit of code, but what made it even more exciting was my belief — hard to imagine now, but not unique in 1985 — that it was already climbing the lower slopes of intelligence.\\n\\nI had gotten into a program at Cornell that didn\\'t make you choose a major. You could take whatever classes you liked, and choose whatever you liked to put on your degree. I of course chose \"Artificial Intelligence.\" When I got the actual physical diploma, I was dismayed to find that the quotes had been included, which made them read as scare-quotes. At the time this bothered me, but now it seems amusingly accurate, for reasons I was about to discover.\\n\\nI applied to 3 grad schools: MIT and Yale, which were renowned for AI at the time, and Harvard, which I\\'d visited because Rich Draves went there, and was also home to Bill Woods, who\\'d invented the type of parser I used in my SHRDLU clone. Only Harvard accepted me, so that was where I went.\\n\\nI don\\'t remember the moment it happened, or if there even was a specific moment, but during the first year of grad school I realized that AI, as practiced at the time, was a hoax. By which I mean the sort of AI in which a program that\\'s told \"the dog is sitting on the chair\" translates this into some formal representation and adds it to the list of things it knows.\\n\\nWhat these programs really showed was that there\\'s a subset of natural language that\\'s a formal language. But a very proper subset. It was clear that there was an unbridgeable gap between what they could do and actually understanding natural language. It was not, in fact, simply a matter of teaching SHRDLU more words. That whole way of doing AI, with explicit data structures representing concepts, was not going to work. Its brokenness did, as so often happens, generate a lot of opportunities to write papers about various band-aids that could be applied to it, but it was never going to get us Mike.\\n\\nSo I looked around to see what I could salvage from the wreckage of my plans, and there was Lisp. I knew from experience that Lisp was interesting for its own sake and not just for its association with AI, even though that was the main reason people cared about it at the time. So I decided to focus on Lisp. In fact, I decided to write a book about Lisp hacking. It\\'s scary to think how little I knew about Lisp hacking when I started writing that book. But there\\'s nothing like writing a book about something to help you learn it. The book, On Lisp, wasn\\'t published till 1993, but I wrote much of it in grad school.\\n\\nComputer Science is an uneasy alliance between two halves, theory and systems. The theory people prove things, and the systems people build things. I wanted to build things.'), Document(id='7b0c53b0-57b4-4730-a8f5-e0154ea702e7', text='When I was dealing with some urgent problem during YC, there was about a 60% chance it had to do with HN, and a 40% chance it had do with everything else combined. [17]\\n\\nAs well as HN, I wrote all of YC\\'s internal software in Arc. But while I continued to work a good deal in Arc, I gradually stopped working on Arc, partly because I didn\\'t have time to, and partly because it was a lot less attractive to mess around with the language now that we had all this infrastructure depending on it. So now my three projects were reduced to two: writing essays and working on YC.\\n\\nYC was different from other kinds of work I\\'ve done. Instead of deciding for myself what to work on, the problems came to me. Every 6 months there was a new batch of startups, and their problems, whatever they were, became our problems. It was very engaging work, because their problems were quite varied, and the good founders were very effective. If you were trying to learn the most you could about startups in the shortest possible time, you couldn\\'t have picked a better way to do it.\\n\\nThere were parts of the job I didn\\'t like. Disputes between cofounders, figuring out when people were lying to us, fighting with people who maltreated the startups, and so on. But I worked hard even at the parts I didn\\'t like. I was haunted by something Kevin Hale once said about companies: \"No one works harder than the boss.\" He meant it both descriptively and prescriptively, and it was the second part that scared me. I wanted YC to be good, so if how hard I worked set the upper bound on how hard everyone else worked, I\\'d better work very hard.\\n\\nOne day in 2010, when he was visiting California for interviews, Robert Morris did something astonishing: he offered me unsolicited advice. I can only remember him doing that once before. One day at Viaweb, when I was bent over double from a kidney stone, he suggested that it would be a good idea for him to take me to the hospital. That was what it took for Rtm to offer unsolicited advice. So I remember his exact words very clearly. \"You know,\" he said, \"you should make sure Y Combinator isn\\'t the last cool thing you do.\"\\n\\nAt the time I didn\\'t understand what he meant, but gradually it dawned on me that he was saying I should quit. This seemed strange advice, because YC was doing great. But if there was one thing rarer than Rtm offering advice, it was Rtm being wrong. So this set me thinking. It was true that on my current trajectory, YC would be the last thing I did, because it was only taking up more of my attention. It had already eaten Arc, and was in the process of eating essays too. Either YC was my life\\'s work or I\\'d have to leave eventually. And it wasn\\'t, so I would.\\n\\nIn the summer of 2012 my mother had a stroke, and the cause turned out to be a blood clot caused by colon cancer. The stroke destroyed her balance, and she was put in a nursing home, but she really wanted to get out of it and back to her house, and my sister and I were determined to help her do it. I used to fly up to Oregon to visit her regularly, and I had a lot of time to think on those flights. On one of them I realized I was ready to hand YC over to someone else.\\n\\nI asked Jessica if she wanted to be president, but she didn\\'t, so we decided we\\'d try to recruit Sam Altman. We talked to Robert and Trevor and we agreed to make it a complete changing of the guard. Up till that point YC had been controlled by the original LLC we four had started. But we wanted YC to last for a long time, and to do that it couldn\\'t be controlled by the founders. So if Sam said yes, we\\'d let him reorganize YC. Robert and I would retire, and Jessica and Trevor would become ordinary partners.\\n\\nWhen we asked Sam if he wanted to be president of YC, initially he said no. He wanted to start a startup to make nuclear reactors. But I kept at it, and in October 2013 he finally agreed. We decided he\\'d take over starting with the winter 2014 batch. For the rest of 2013 I left running YC more and more to Sam, partly so he could learn the job, and partly because I was focused on my mother, whose cancer had returned.')]\n"
     ]
    }
   ],
   "source": [
    "llm_response = await chat_engine.astream_chat(question)\n",
    "await llm_response.aprint_response_stream()\n",
    "print(\"Citations: \")\n",
    "print(llm_response.citations)\n",
    "print(\"Documents: \")\n",
    "print(llm_response.documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
