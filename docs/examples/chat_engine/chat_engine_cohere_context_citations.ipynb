{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a9691d675c518e9",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/EugeneLightsOn/llama_index/blob/cohere_context_chat_plus_citations/docs/examples/chat_engine/chat_engine_cohere_context_citations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b938b29100cde228",
   "metadata": {},
   "source": [
    "Cohere Chat Engine with citations and documents - Usage Example\n",
    "========================================\n",
    "    \n",
    "This notebook demonstrates how to use the Cohere chat engine to generate responses to user input with citations and context documents(Cohere documents mode - see the documentation [here](https://docs.cohere.com/docs/retrieval-augmented-generation-rag) and [here](https://docs.cohere.com/docs/retrieval-augmented-generation-rag). Cohere Chat Engine provides several modes for generating responses, including: Chat, Async Chat, Stream Chat and Async Stream Chat. We will use OpenSearch as a vector index to retrieve the context documents and the next sample [data](https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt) \n",
    "\n",
    "\n",
    "\n",
    "Download Data\n",
    "========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9ba7968d75b307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-21 13:47:16--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 75042 (73K) [text/plain]\r\n",
      "Saving to: ‘data/paul_graham/paul_graham_essay.txt’\r\n",
      "\r\n",
      "data/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.06s   \r\n",
      "\r\n",
      "2024-02-21 13:47:17 (1.29 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2165c037b8c63bcd",
   "metadata": {},
   "source": [
    "Install requirements\n",
    "========================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce05a5b1d0199c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in ./.venv/lib/python3.11/site-packages (0.9.39)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (2.0.25)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.11/site-packages (from llama-index) (3.9.3)\r\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.11/site-packages (from llama-index) (0.6.3)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.11/site-packages (from llama-index) (1.2.14)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from llama-index) (2023.12.2)\r\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.11/site-packages (from llama-index) (0.26.0)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.11/site-packages (from llama-index) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.11/site-packages (from llama-index) (3.2.1)\r\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.venv/lib/python3.11/site-packages (from llama-index) (3.8.1)\r\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from llama-index) (1.26.3)\r\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.11/site-packages (from llama-index) (1.10.0)\r\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (from llama-index) (2.2.0)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.11/site-packages (from llama-index) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in ./.venv/lib/python3.11/site-packages (from llama-index) (8.2.3)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.11/site-packages (from llama-index) (0.5.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.11/site-packages (from llama-index) (4.9.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.11/site-packages (from llama-index) (0.9.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (23.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.9.4)\r\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index) (1.16.0)\r\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (8.1.3)\r\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (1.3.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (2023.12.25)\r\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (4.66.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai>=1.1.0->llama-index) (4.2.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai>=1.1.0->llama-index) (1.9.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.11/site-packages (from openai>=1.1.0->llama-index) (2.6.0)\r\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai>=1.1.0->llama-index) (1.3.0)\r\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx->llama-index) (2023.7.22)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx->llama-index) (1.0.2)\r\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.11/site-packages (from httpx->llama-index) (3.4)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index) (0.14.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index) (3.1.0)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index) (1.26.18)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (3.0.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index) (1.0.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json->llama-index) (3.20.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->llama-index) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas->llama-index) (2023.4)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas->llama-index) (2023.4)\r\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index) (23.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index) (2.16.1)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index) (1.16.0)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: cohere in ./.venv/lib/python3.11/site-packages (4.45)\r\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.0 in ./.venv/lib/python3.11/site-packages (from cohere) (3.9.3)\r\n",
      "Requirement already satisfied: backoff<3.0,>=2.0 in ./.venv/lib/python3.11/site-packages (from cohere) (2.2.1)\r\n",
      "Requirement already satisfied: fastavro<2.0,>=1.8 in ./.venv/lib/python3.11/site-packages (from cohere) (1.9.3)\r\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in ./.venv/lib/python3.11/site-packages (from cohere) (6.11.0)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.0 in ./.venv/lib/python3.11/site-packages (from cohere) (2.31.0)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in ./.venv/lib/python3.11/site-packages (from cohere) (1.26.18)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\r\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.11/site-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.25.0->cohere) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.25.0->cohere) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.7.22)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index\n",
    "%pip install cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe1a51034616ee6",
   "metadata": {},
   "source": [
    "Let's start by creating a new index and adding the context documents into it.\n",
    "========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d728e6c512eaf",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3db338063b98b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from llama_index.embeddings.cohereai import CohereEmbedding\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    ServiceContext,\n",
    ")\n",
    "from llama_index.vector_stores import (\n",
    "    OpensearchVectorStore,\n",
    "    OpensearchVectorClient,\n",
    ")\n",
    "\n",
    "from llama_index.llms import Cohere, ChatMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516e2f2da08f6b9",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a64b6255b4bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"COHERE_API_KEY\"] = \"COHERE_API_KEY_HERE\"\n",
    "COHERE_API_KEY = os.environ[\"COHERE_API_KEY\"]\n",
    "OPENSEARCH_URL = \"http://localhost:9200\"\n",
    "OPENSEARCH_INDEX_NAME = \"idx_paul_graham_essay\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd78554cf75b40",
   "metadata": {},
   "source": [
    "### Create a new Cohere LLM instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1904b8b2d3fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = Cohere(\n",
    "    \"command\",\n",
    "    api_key=COHERE_API_KEY,\n",
    "    temperature=0.5,\n",
    "    additional_kwargs={\"prompt_truncation\": \"AUTO\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1763b8035a964c88",
   "metadata": {},
   "source": [
    "### Create a new Cohere embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24545f37bb8b72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cohere_embed_model(\n",
    "    input_type=\"search_document\", model_name=\"embed-english-v3.0\"\n",
    "):\n",
    "    cohere_embed_model = CohereEmbedding(\n",
    "        cohere_api_key=COHERE_API_KEY,\n",
    "        model_name=model_name,\n",
    "        input_type=input_type,\n",
    "    )\n",
    "\n",
    "    return cohere_embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32147d36841884af",
   "metadata": {},
   "source": [
    "### Create a new service context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c066f044e8bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cohere_service_context(input_type=\"search_document\"):\n",
    "    cohere_service_context = ServiceContext.from_defaults(\n",
    "        llm=LLM, embed_model=get_cohere_embed_model(input_type=input_type)\n",
    "    )\n",
    "    return cohere_service_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab97d706dc60a00b",
   "metadata": {},
   "source": [
    "### Create a new open search vector client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f3685bbcbb90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opensearch_store_client(\n",
    "    host=\"http://localhost:9200\",\n",
    "    size=1024,\n",
    "    embedding_field=\"passage_embedding\",\n",
    "    text_field=\"passage_text\",\n",
    "):\n",
    "    opensearch_store_client = OpensearchVectorClient(\n",
    "        host,\n",
    "        OPENSEARCH_INDEX_NAME,\n",
    "        size,\n",
    "        embedding_field=embedding_field,\n",
    "        text_field=text_field,\n",
    "    )\n",
    "\n",
    "    return opensearch_store_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c974fd92480701",
   "metadata": {},
   "source": [
    "### Read the sample documents from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385194abb2092df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_documents(path=\"./data/paul_graham/\"):\n",
    "    sample_documents = SimpleDirectoryReader(path).load_data()\n",
    "    return sample_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6bd9f75ddf5301",
   "metadata": {},
   "source": [
    "### Create a new Opensearch vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e358f286c6de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opensearch_vector_store():\n",
    "    opensearch_vector_store = OpensearchVectorStore(\n",
    "        get_opensearch_store_client()\n",
    "    )\n",
    "\n",
    "    return opensearch_vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3a44e1cd154046",
   "metadata": {},
   "source": [
    "### Create a new storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6562d80c0c184757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opensearch_storage_context():\n",
    "    opensearch_storage_context = StorageContext.from_defaults(\n",
    "        vector_store=get_opensearch_vector_store()\n",
    "    )\n",
    "    return opensearch_storage_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608da21a6ac0dea1",
   "metadata": {},
   "source": [
    "### Create a new vector store index and fill it with the sample documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100bb0e415a53dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_opensearch_documents_index():\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents=get_sample_documents(),\n",
    "        service_context=get_cohere_service_context(),\n",
    "        storage_context=get_opensearch_storage_context(),\n",
    "    )\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ddeb14cb1cf463",
   "metadata": {},
   "source": [
    "### For the Chat Engine we should use Cohere embed model with input type \"search_query\". See the [documentation](https://docs.cohere.com/reference/embed) for more details. So we need to use a new index with the input type \"search_query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e16a59f288f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opensearch_query_index():\n",
    "    opensearch_store = get_opensearch_vector_store()\n",
    "    opensearch_context = get_cohere_service_context(input_type=\"search_query\")\n",
    "    index = VectorStoreIndex.from_vector_store(\n",
    "        opensearch_store, service_context=opensearch_context\n",
    "    )\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287d65e488123bb",
   "metadata": {},
   "source": [
    "### And finally, we can create a new chat engine using Cohere Context mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185577d42fb1080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_engine_by_index_and_mode(index, mode=\"cohere_context\"):\n",
    "    service_context = get_cohere_service_context(input_type=\"search_query\")\n",
    "    chat_engine = index.as_chat_engine(\n",
    "        service_context=service_context, chat_mode=mode\n",
    "    )\n",
    "    return chat_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bee302f3959a6c2",
   "metadata": {},
   "source": [
    "## Let's run it and see the results\n",
    "### Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5c3e4d2c58e985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham reverse-engineered SHRDLU for his undergraduate thesis. SHRDLU was a PBS documentary that showed Terry Winograd using the SHRDLU program. Paul Graham was drawn to working on AI after seeing the demo of SHRDLU in the documentary and eventually focused on the Lisp language after deciding AI, as practiced then, was a hoax.\n",
      "Citations: [{'start': 12, 'end': 37, 'text': 'reverse-engineered SHRDLU', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}, {'start': 46, 'end': 67, 'text': 'undergraduate thesis.', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}, {'start': 81, 'end': 96, 'text': 'PBS documentary', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}, {'start': 109, 'end': 123, 'text': 'Terry Winograd', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}, {'start': 270, 'end': 283, 'text': 'Lisp language', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}, {'start': 299, 'end': 333, 'text': 'AI, as practiced then, was a hoax.', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}]\n",
      "Documents: [{'id': '68841b92-0964-4488-a4b9-883dd26288ce', 'text': 'I couldn\\'t have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\\n\\nAI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven\\'t tried rereading The Moon is a Harsh Mistress, so I don\\'t know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we\\'d have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most. All you had to do was teach SHRDLU more words.\\n\\nThere weren\\'t any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp, since in those days Lisp was regarded as the language of AI. The commonly used programming languages then were pretty primitive, and programmers\\' ideas correspondingly so. The default language at Cornell was a Pascal-like language called PL/I, and the situation was similar elsewhere. Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were. This was more like it; this was what I had expected college to do. It wasn\\'t happening in a class, like it was supposed to, but that was ok. For the next couple years I was on a roll. I knew what I was going to do.\\n\\nFor my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program. It was a pleasing bit of code, but what made it even more exciting was my belief — hard to imagine now, but not unique in 1985 — that it was already climbing the lower slopes of intelligence.\\n\\nI had gotten into a program at Cornell that didn\\'t make you choose a major. You could take whatever classes you liked, and choose whatever you liked to put on your degree. I of course chose \"Artificial Intelligence.\" When I got the actual physical diploma, I was dismayed to find that the quotes had been included, which made them read as scare-quotes. At the time this bothered me, but now it seems amusingly accurate, for reasons I was about to discover.\\n\\nI applied to 3 grad schools: MIT and Yale, which were renowned for AI at the time, and Harvard, which I\\'d visited because Rich Draves went there, and was also home to Bill Woods, who\\'d invented the type of parser I used in my SHRDLU clone. Only Harvard accepted me, so that was where I went.\\n\\nI don\\'t remember the moment it happened, or if there even was a specific moment, but during the first year of grad school I realized that AI, as practiced at the time, was a hoax. By which I mean the sort of AI in which a program that\\'s told \"the dog is sitting on the chair\" translates this into some formal representation and adds it to the list of things it knows.\\n\\nWhat these programs really showed was that there\\'s a subset of natural language that\\'s a formal language. But a very proper subset. It was clear that there was an unbridgeable gap between what they could do and actually understanding natural language. It was not, in fact, simply a matter of teaching SHRDLU more words. That whole way of doing AI, with explicit data structures representing concepts, was not going to work. Its brokenness did, as so often happens, generate a lot of opportunities to write papers about various band-aids that could be applied to it, but it was never going to get us Mike.\\n\\nSo I looked around to see what I could salvage from the wreckage of my plans, and there was Lisp. I knew from experience that Lisp was interesting for its own sake and not just for its association with AI, even though that was the main reason people cared about it at the time. So I decided to focus on Lisp. In fact, I decided to write a book about Lisp hacking. It\\'s scary to think how little I knew about Lisp hacking when I started writing that book. But there\\'s nothing like writing a book about something to help you learn it. The book, On Lisp, wasn\\'t published till 1993, but I wrote much of it in grad school.\\n\\nComputer Science is an uneasy alliance between two halves, theory and systems. The theory people prove things, and the systems people build things. I wanted to build things.'}]\n"
     ]
    }
   ],
   "source": [
    "# Create a new index and fill it with the sample documents run it if the index is not created yet. Just comment it after the first run\n",
    "fill_opensearch_documents_index()\n",
    "\n",
    "# Create a new chat engine\n",
    "chat_engine = get_chat_engine_by_index_and_mode(get_opensearch_query_index())\n",
    "\n",
    "# Ask a question using the chat engine\n",
    "question = \"What did Paul Graham do with SHRDLU?\"\n",
    "llm_response = chat_engine.chat(question)\n",
    "# Print the response\n",
    "print(llm_response)\n",
    "# Print the citations\n",
    "print(f\"Citations: {llm_response.citations}\")\n",
    "# Print the context documents\n",
    "print(f\"Documents: {llm_response.documents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb63af9016036ad",
   "metadata": {},
   "source": [
    "### Async Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21667cd91877db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For his undergraduate thesis, Paul Graham reverse-engineered Shrdlu. He later wrote about his experience with Shrdlu and his motivations for working with Lisp in an essay titled \"The Acceleration of Addict Formation\", where he discusses the increasing incentive for creating new hacks instead of focusing on the original goal of the project.\n",
      "Citations: [{'start': 8, 'end': 28, 'text': 'undergraduate thesis', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}, {'start': 42, 'end': 68, 'text': 'reverse-engineered Shrdlu.', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}]\n",
      "Documents: [{'id': '68841b92-0964-4488-a4b9-883dd26288ce', 'text': 'I couldn\\'t have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\\n\\nAI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven\\'t tried rereading The Moon is a Harsh Mistress, so I don\\'t know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we\\'d have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most. All you had to do was teach SHRDLU more words.\\n\\nThere weren\\'t any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp, since in those days Lisp was regarded as the language of AI. The commonly used programming languages then were pretty primitive, and programmers\\' ideas correspondingly so. The default language at Cornell was a Pascal-like language called PL/I, and the situation was similar elsewhere. Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were. This was more like it; this was what I had expected college to do. It wasn\\'t happening in a class, like it was supposed to, but that was ok. For the next couple years I was on a roll. I knew what I was going to do.\\n\\nFor my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program. It was a pleasing bit of code, but what made it even more exciting was my belief — hard to imagine now, but not unique in 1985 — that it was already climbing the lower slopes of intelligence.\\n\\nI had gotten into a program at Cornell that didn\\'t make you choose a major. You could take whatever classes you liked, and choose whatever you liked to put on your degree. I of course chose \"Artificial Intelligence.\" When I got the actual physical diploma, I was dismayed to find that the quotes had been included, which made them read as scare-quotes. At the time this bothered me, but now it seems amusingly accurate, for reasons I was about to discover.\\n\\nI applied to 3 grad schools: MIT and Yale, which were renowned for AI at the time, and Harvard, which I\\'d visited because Rich Draves went there, and was also home to Bill Woods, who\\'d invented the type of parser I used in my SHRDLU clone. Only Harvard accepted me, so that was where I went.\\n\\nI don\\'t remember the moment it happened, or if there even was a specific moment, but during the first year of grad school I realized that AI, as practiced at the time, was a hoax. By which I mean the sort of AI in which a program that\\'s told \"the dog is sitting on the chair\" translates this into some formal representation and adds it to the list of things it knows.\\n\\nWhat these programs really showed was that there\\'s a subset of natural language that\\'s a formal language. But a very proper subset. It was clear that there was an unbridgeable gap between what they could do and actually understanding natural language. It was not, in fact, simply a matter of teaching SHRDLU more words. That whole way of doing AI, with explicit data structures representing concepts, was not going to work. Its brokenness did, as so often happens, generate a lot of opportunities to write papers about various band-aids that could be applied to it, but it was never going to get us Mike.\\n\\nSo I looked around to see what I could salvage from the wreckage of my plans, and there was Lisp. I knew from experience that Lisp was interesting for its own sake and not just for its association with AI, even though that was the main reason people cared about it at the time. So I decided to focus on Lisp. In fact, I decided to write a book about Lisp hacking. It\\'s scary to think how little I knew about Lisp hacking when I started writing that book. But there\\'s nothing like writing a book about something to help you learn it. The book, On Lisp, wasn\\'t published till 1993, but I wrote much of it in grad school.\\n\\nComputer Science is an uneasy alliance between two halves, theory and systems. The theory people prove things, and the systems people build things. I wanted to build things.'}]\n"
     ]
    }
   ],
   "source": [
    "llm_response = await chat_engine.achat(question)\n",
    "print(llm_response)\n",
    "print(f\"Citations: {llm_response.citations}\")\n",
    "print(f\"Documents: {llm_response.documents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6733606f1fa71a60",
   "metadata": {},
   "source": [
    "### Stream Chat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefefe581650b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For his undergraduate thesis, Paul Graham reverse-engineered SHRDLU. He later wrote about his experience with SHRDLU and his motivations for working with Lisp in an essay titled \"The Acceleration of Addict Formation\", where he discusses the increasing incentive for creating new hacks instead of focusing on the original goal of the project.Citations: \n",
      "[{'start': 8, 'end': 28, 'text': 'undergraduate thesis', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}][{'start': 42, 'end': 68, 'text': 'reverse-engineered SHRDLU.', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}][{'start': 94, 'end': 116, 'text': 'experience with SHRDLU', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}][{'start': 125, 'end': 158, 'text': 'motivations for working with Lisp', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}][{'start': 178, 'end': 216, 'text': '\"The Acceleration of Addict Formation\"', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}][{'start': 266, 'end': 284, 'text': 'creating new hacks', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}][{'start': 312, 'end': 341, 'text': 'original goal of the project.', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}]Documents: \n",
      "[{'id': '68841b92-0964-4488-a4b9-883dd26288ce', 'text': 'I couldn\\'t have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\\n\\nAI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven\\'t tried rereading The Moon is a Harsh Mistress, so I don\\'t know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we\\'d have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most. All you had to do was teach SHRDLU more words.\\n\\nThere weren\\'t any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp, since in those days Lisp was regarded as the language of AI. The commonly used programming languages then were pretty primitive, and programmers\\' ideas correspondingly so. The default language at Cornell was a Pascal-like language called PL/I, and the situation was similar elsewhere. Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were. This was more like it; this was what I had expected college to do. It wasn\\'t happening in a class, like it was supposed to, but that was ok. For the next couple years I was on a roll. I knew what I was going to do.\\n\\nFor my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program. It was a pleasing bit of code, but what made it even more exciting was my belief — hard to imagine now, but not unique in 1985 — that it was already climbing the lower slopes of intelligence.\\n\\nI had gotten into a program at Cornell that didn\\'t make you choose a major. You could take whatever classes you liked, and choose whatever you liked to put on your degree. I of course chose \"Artificial Intelligence.\" When I got the actual physical diploma, I was dismayed to find that the quotes had been included, which made them read as scare-quotes. At the time this bothered me, but now it seems amusingly accurate, for reasons I was about to discover.\\n\\nI applied to 3 grad schools: MIT and Yale, which were renowned for AI at the time, and Harvard, which I\\'d visited because Rich Draves went there, and was also home to Bill Woods, who\\'d invented the type of parser I used in my SHRDLU clone. Only Harvard accepted me, so that was where I went.\\n\\nI don\\'t remember the moment it happened, or if there even was a specific moment, but during the first year of grad school I realized that AI, as practiced at the time, was a hoax. By which I mean the sort of AI in which a program that\\'s told \"the dog is sitting on the chair\" translates this into some formal representation and adds it to the list of things it knows.\\n\\nWhat these programs really showed was that there\\'s a subset of natural language that\\'s a formal language. But a very proper subset. It was clear that there was an unbridgeable gap between what they could do and actually understanding natural language. It was not, in fact, simply a matter of teaching SHRDLU more words. That whole way of doing AI, with explicit data structures representing concepts, was not going to work. Its brokenness did, as so often happens, generate a lot of opportunities to write papers about various band-aids that could be applied to it, but it was never going to get us Mike.\\n\\nSo I looked around to see what I could salvage from the wreckage of my plans, and there was Lisp. I knew from experience that Lisp was interesting for its own sake and not just for its association with AI, even though that was the main reason people cared about it at the time. So I decided to focus on Lisp. In fact, I decided to write a book about Lisp hacking. It\\'s scary to think how little I knew about Lisp hacking when I started writing that book. But there\\'s nothing like writing a book about something to help you learn it. The book, On Lisp, wasn\\'t published till 1993, but I wrote much of it in grad school.\\n\\nComputer Science is an uneasy alliance between two halves, theory and systems. The theory people prove things, and the systems people build things. I wanted to build things.'}, {'id': '8ced7939-1836-4327-a990-db1693974b1e', 'text': 'When I was dealing with some urgent problem during YC, there was about a 60% chance it had to do with HN, and a 40% chance it had do with everything else combined. [17]\\n\\nAs well as HN, I wrote all of YC\\'s internal software in Arc. But while I continued to work a good deal in Arc, I gradually stopped working on Arc, partly because I didn\\'t have time to, and partly because it was a lot less attractive to mess around with the language now that we had all this infrastructure depending on it. So now my three projects were reduced to two: writing essays and working on YC.\\n\\nYC was different from other kinds of work I\\'ve done. Instead of deciding for myself what to work on, the problems came to me. Every 6 months there was a new batch of startups, and their problems, whatever they were, became our problems. It was very engaging work, because their problems were quite varied, and the good founders were very effective. If you were trying to learn the most you could about startups in the shortest possible time, you couldn\\'t have picked a better way to do it.\\n\\nThere were parts of the job I didn\\'t like. Disputes between cofounders, figuring out when people were lying to us, fighting with people who maltreated the startups, and so on. But I worked hard even at the parts I didn\\'t like. I was haunted by something Kevin Hale once said about companies: \"No one works harder than the boss.\" He meant it both descriptively and prescriptively, and it was the second part that scared me. I wanted YC to be good, so if how hard I worked set the upper bound on how hard everyone else worked, I\\'d better work very hard.\\n\\nOne day in 2010, when he was visiting California for interviews, Robert Morris did something astonishing: he offered me unsolicited advice. I can only remember him doing that once before. One day at Viaweb, when I was bent over double from a kidney stone, he suggested that it would be a good idea for him to take me to the hospital. That was what it took for Rtm to offer unsolicited advice. So I remember his exact words very clearly. \"You know,\" he said, \"you should make sure Y Combinator isn\\'t the last cool thing you do.\"\\n\\nAt the time I didn\\'t understand what he meant, but gradually it dawned on me that he was saying I should quit. This seemed strange advice, because YC was doing great. But if there was one thing rarer than Rtm offering advice, it was Rtm being wrong. So this set me thinking. It was true that on my current trajectory, YC would be the last thing I did, because it was only taking up more of my attention. It had already eaten Arc, and was in the process of eating essays too. Either YC was my life\\'s work or I\\'d have to leave eventually. And it wasn\\'t, so I would.\\n\\nIn the summer of 2012 my mother had a stroke, and the cause turned out to be a blood clot caused by colon cancer. The stroke destroyed her balance, and she was put in a nursing home, but she really wanted to get out of it and back to her house, and my sister and I were determined to help her do it. I used to fly up to Oregon to visit her regularly, and I had a lot of time to think on those flights. On one of them I realized I was ready to hand YC over to someone else.\\n\\nI asked Jessica if she wanted to be president, but she didn\\'t, so we decided we\\'d try to recruit Sam Altman. We talked to Robert and Trevor and we agreed to make it a complete changing of the guard. Up till that point YC had been controlled by the original LLC we four had started. But we wanted YC to last for a long time, and to do that it couldn\\'t be controlled by the founders. So if Sam said yes, we\\'d let him reorganize YC. Robert and I would retire, and Jessica and Trevor would become ordinary partners.\\n\\nWhen we asked Sam if he wanted to be president of YC, initially he said no. He wanted to start a startup to make nuclear reactors. But I kept at it, and in October 2013 he finally agreed. We decided he\\'d take over starting with the winter 2014 batch. For the rest of 2013 I left running YC more and more to Sam, partly so he could learn the job, and partly because I was focused on my mother, whose cancer had returned.'}]"
     ]
    }
   ],
   "source": [
    "llm_response = chat_engine.stream_chat(question)\n",
    "llm_response.print_response_stream()\n",
    "\n",
    "print(\"Citations: \")\n",
    "llm_response.print_citations_stream()\n",
    "\n",
    "print(\"Documents: \")\n",
    "llm_response.print_documents_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b31467e7c26b2",
   "metadata": {},
   "source": [
    "### Async Stream Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437fd5ec78dd905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For his undergraduate thesis, Paul Graham reverse-engineered SHRDLU. He later wrote about his experience with SHRDLU and his motivations for working with Lisp in an essay titled \"The Acceleration of Addict Formation\", where he discusses the increasing incentive for creating new hacks instead of focusing on the original goal of the project.Citations: \n",
      "[{'start': 8, 'end': 28, 'text': 'undergraduate thesis', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}][{'start': 42, 'end': 68, 'text': 'reverse-engineered SHRDLU.', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}][{'start': 94, 'end': 116, 'text': 'experience with SHRDLU', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}][{'start': 125, 'end': 158, 'text': 'motivations for working with Lisp', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}][{'start': 178, 'end': 216, 'text': '\"The Acceleration of Addict Formation\"', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}][{'start': 266, 'end': 284, 'text': 'creating new hacks', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}][{'start': 312, 'end': 341, 'text': 'original goal of the project.', 'document_ids': ['68841b92-0964-4488-a4b9-883dd26288ce']}]Documents: \n",
      "[{'id': '68841b92-0964-4488-a4b9-883dd26288ce', 'text': 'I couldn\\'t have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\\n\\nAI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven\\'t tried rereading The Moon is a Harsh Mistress, so I don\\'t know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we\\'d have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most. All you had to do was teach SHRDLU more words.\\n\\nThere weren\\'t any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp, since in those days Lisp was regarded as the language of AI. The commonly used programming languages then were pretty primitive, and programmers\\' ideas correspondingly so. The default language at Cornell was a Pascal-like language called PL/I, and the situation was similar elsewhere. Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were. This was more like it; this was what I had expected college to do. It wasn\\'t happening in a class, like it was supposed to, but that was ok. For the next couple years I was on a roll. I knew what I was going to do.\\n\\nFor my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program. It was a pleasing bit of code, but what made it even more exciting was my belief — hard to imagine now, but not unique in 1985 — that it was already climbing the lower slopes of intelligence.\\n\\nI had gotten into a program at Cornell that didn\\'t make you choose a major. You could take whatever classes you liked, and choose whatever you liked to put on your degree. I of course chose \"Artificial Intelligence.\" When I got the actual physical diploma, I was dismayed to find that the quotes had been included, which made them read as scare-quotes. At the time this bothered me, but now it seems amusingly accurate, for reasons I was about to discover.\\n\\nI applied to 3 grad schools: MIT and Yale, which were renowned for AI at the time, and Harvard, which I\\'d visited because Rich Draves went there, and was also home to Bill Woods, who\\'d invented the type of parser I used in my SHRDLU clone. Only Harvard accepted me, so that was where I went.\\n\\nI don\\'t remember the moment it happened, or if there even was a specific moment, but during the first year of grad school I realized that AI, as practiced at the time, was a hoax. By which I mean the sort of AI in which a program that\\'s told \"the dog is sitting on the chair\" translates this into some formal representation and adds it to the list of things it knows.\\n\\nWhat these programs really showed was that there\\'s a subset of natural language that\\'s a formal language. But a very proper subset. It was clear that there was an unbridgeable gap between what they could do and actually understanding natural language. It was not, in fact, simply a matter of teaching SHRDLU more words. That whole way of doing AI, with explicit data structures representing concepts, was not going to work. Its brokenness did, as so often happens, generate a lot of opportunities to write papers about various band-aids that could be applied to it, but it was never going to get us Mike.\\n\\nSo I looked around to see what I could salvage from the wreckage of my plans, and there was Lisp. I knew from experience that Lisp was interesting for its own sake and not just for its association with AI, even though that was the main reason people cared about it at the time. So I decided to focus on Lisp. In fact, I decided to write a book about Lisp hacking. It\\'s scary to think how little I knew about Lisp hacking when I started writing that book. But there\\'s nothing like writing a book about something to help you learn it. The book, On Lisp, wasn\\'t published till 1993, but I wrote much of it in grad school.\\n\\nComputer Science is an uneasy alliance between two halves, theory and systems. The theory people prove things, and the systems people build things. I wanted to build things.'}, {'id': '8ced7939-1836-4327-a990-db1693974b1e', 'text': 'When I was dealing with some urgent problem during YC, there was about a 60% chance it had to do with HN, and a 40% chance it had do with everything else combined. [17]\\n\\nAs well as HN, I wrote all of YC\\'s internal software in Arc. But while I continued to work a good deal in Arc, I gradually stopped working on Arc, partly because I didn\\'t have time to, and partly because it was a lot less attractive to mess around with the language now that we had all this infrastructure depending on it. So now my three projects were reduced to two: writing essays and working on YC.\\n\\nYC was different from other kinds of work I\\'ve done. Instead of deciding for myself what to work on, the problems came to me. Every 6 months there was a new batch of startups, and their problems, whatever they were, became our problems. It was very engaging work, because their problems were quite varied, and the good founders were very effective. If you were trying to learn the most you could about startups in the shortest possible time, you couldn\\'t have picked a better way to do it.\\n\\nThere were parts of the job I didn\\'t like. Disputes between cofounders, figuring out when people were lying to us, fighting with people who maltreated the startups, and so on. But I worked hard even at the parts I didn\\'t like. I was haunted by something Kevin Hale once said about companies: \"No one works harder than the boss.\" He meant it both descriptively and prescriptively, and it was the second part that scared me. I wanted YC to be good, so if how hard I worked set the upper bound on how hard everyone else worked, I\\'d better work very hard.\\n\\nOne day in 2010, when he was visiting California for interviews, Robert Morris did something astonishing: he offered me unsolicited advice. I can only remember him doing that once before. One day at Viaweb, when I was bent over double from a kidney stone, he suggested that it would be a good idea for him to take me to the hospital. That was what it took for Rtm to offer unsolicited advice. So I remember his exact words very clearly. \"You know,\" he said, \"you should make sure Y Combinator isn\\'t the last cool thing you do.\"\\n\\nAt the time I didn\\'t understand what he meant, but gradually it dawned on me that he was saying I should quit. This seemed strange advice, because YC was doing great. But if there was one thing rarer than Rtm offering advice, it was Rtm being wrong. So this set me thinking. It was true that on my current trajectory, YC would be the last thing I did, because it was only taking up more of my attention. It had already eaten Arc, and was in the process of eating essays too. Either YC was my life\\'s work or I\\'d have to leave eventually. And it wasn\\'t, so I would.\\n\\nIn the summer of 2012 my mother had a stroke, and the cause turned out to be a blood clot caused by colon cancer. The stroke destroyed her balance, and she was put in a nursing home, but she really wanted to get out of it and back to her house, and my sister and I were determined to help her do it. I used to fly up to Oregon to visit her regularly, and I had a lot of time to think on those flights. On one of them I realized I was ready to hand YC over to someone else.\\n\\nI asked Jessica if she wanted to be president, but she didn\\'t, so we decided we\\'d try to recruit Sam Altman. We talked to Robert and Trevor and we agreed to make it a complete changing of the guard. Up till that point YC had been controlled by the original LLC we four had started. But we wanted YC to last for a long time, and to do that it couldn\\'t be controlled by the founders. So if Sam said yes, we\\'d let him reorganize YC. Robert and I would retire, and Jessica and Trevor would become ordinary partners.\\n\\nWhen we asked Sam if he wanted to be president of YC, initially he said no. He wanted to start a startup to make nuclear reactors. But I kept at it, and in October 2013 he finally agreed. We decided he\\'d take over starting with the winter 2014 batch. For the rest of 2013 I left running YC more and more to Sam, partly so he could learn the job, and partly because I was focused on my mother, whose cancer had returned.'}]"
     ]
    }
   ],
   "source": [
    "llm_response = await chat_engine.astream_chat(question)\n",
    "await llm_response.aprint_response_stream()\n",
    "print(\"Citations: \")\n",
    "await llm_response.aprint_citations_stream()\n",
    "print(\"Documents: \")\n",
    "await llm_response.aprint_documents_stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
